# llm_w_frontend
This repository is for the local LLM ask-and-answer chat interface with resources. These resources are ‘ephemeral’ in nature, meaning that they are used during questioning only. No data shall be saved.
